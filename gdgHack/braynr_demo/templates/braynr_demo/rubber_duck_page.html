<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Braynr - Rubber Duck Mode</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            padding-top: 20px;
            background-color: #f8f9fa;
        }
        .container {
            max-width: 800px;
            background-color: #ffffff;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 0 15px rgba(0,0,0,0.1);
        }
        h1, h2 {
            color: #343a40;
            margin-bottom: 20px;
        }
        .btn-custom {
            margin-right: 10px;
        }
        #feedbackArea, #spiegazioneArea, #pdfStatusArea {
            margin-top: 15px;
            padding: 15px;
            border: 1px solid #ced4da;
            border-radius: 4px;
            background-color: #e9ecef;
            min-height: 60px;
        }
        #spiegazioneArea { background-color: #f8f9fa; }
        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="text-center">Braynr - Rubber Duck Mode (2-Step Flow)</h1>
        <hr>

        <!-- Fase 1: Caricamento e Processamento PDF -->
        <h2>Step 1: Provide Study Material</h2>
        <div class="mb-3">
            <label for="pdfFile" class="form-label"><strong>Upload Study Material PDF:</strong></label>
            <input class="form-control" type="file" id="pdfFile" accept=".pdf">
        </div>
        <div class="mb-3">
            <label for="materialeStudioText" class="form-label"><strong>Or Paste Text (used if no PDF is uploaded):</strong></label>
            <textarea class="form-control" id="materialeStudioText" rows="3" placeholder="Alternative or additional text..."></textarea>
        </div>
        <button id="btnProcessMaterial" class="btn btn-info mb-3">Upload Material & Prepare Agent</button>
        
        <div id="pdfStatusArea" class="hidden">
            Processing material status...
        </div>

        <!-- Fase 2: Spiegazione Utente -->
        <h2 id="fase2Title" class="hidden">Step 2: Your Vocal Explanation</h2>
        <div id="recordingControls" class="hidden">
            <div class="mb-3 text-center">
                <button id="btnStartRecording" class="btn btn-success btn-custom">Start Explaining</button>
                <button id="btnStopRecording" class="btn btn-danger btn-custom" disabled>Stop Explaining</button>
            </div>
            <div class="mb-3">
                <label class="form-label"><strong>Recording Status:</strong></label>
                <p id="statusMessage" class="form-text">Ready to start...</p>
            </div>
            <div class="mb-3">
                <label class="form-label"><strong>Your Explanation (recognized text):</strong></label>
                <div id="spiegazioneArea">
                    The recognized text from your explanation will appear here...
                </div>
            </div>
        </div>

        <!-- Risultati e Controlli TTS -->
        <div id="resultsArea" class="hidden">
            <h2>Feedback from Agent</h2>
            <div id="feedbackArea">
                The AI's feedback will appear here...
            </div>
            <div id="ttsControls" class="mt-2" style="display: none;">
                <button id="btnPlayPauseResponse" class="btn btn-success btn-sm me-2">Read Response</button>
                <button id="btnStopTTSResponse" class="btn btn-danger btn-sm me-2">Stop Reading</button>
                <button id="btnReplayResponse" class="btn btn-info btn-sm">Replay</button>
                <label for="speedControl" class="form-label ms-3">Speed:</label>
                <input type="range" class="form-range w-25 d-inline-block align-middle" id="speedControl" min="0.5" max="2" value="1" step="0.1">
            </div>
        </div>
    </div>

    <!-- Bootstrap JS Bundle (Popper.js incluso) -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        // DOM Elements - Step 1
        const pdfFileInput = document.getElementById('pdfFile');
        const materialeStudioTextarea = document.getElementById('materialeStudioText');
        const btnProcessMaterial = document.getElementById('btnProcessMaterial');
        const pdfStatusArea = document.getElementById('pdfStatusArea');

        // DOM Elements - Step 2
        const fase2Title = document.getElementById('fase2Title');
        const recordingControls = document.getElementById('recordingControls');
        const btnStartRecording = document.getElementById('btnStartRecording');
        const btnStopRecording = document.getElementById('btnStopRecording');
        const statusMessage = document.getElementById('statusMessage');
        const spiegazioneArea = document.getElementById('spiegazioneArea');

        // DOM Elements - Results
        const resultsArea = document.getElementById('resultsArea');
        const feedbackArea = document.getElementById('feedbackArea');
        const ttsControls = document.getElementById('ttsControls');
        const btnPlayPauseResponse = document.getElementById('btnPlayPauseResponse');
        const btnStopTTSResponse = document.getElementById('btnStopTTSResponse');
        const btnReplayResponse = document.getElementById('btnReplayResponse');
        const speedControl = document.getElementById('speedControl');

        let recognition = null;
        let transcriptText = '';
        let agentResponseText = '';
        let currentUtterance = null; // To keep track of the last utterance

        // URLs (make sure app_name is correct in your braynr_demo urls.py)
        const processPdfUrl = "{% url 'braynr_demo:process_pdf' %}";
        const processAudioUrl = "{% url 'braynr_demo:process_audio' %}";

        // --- Initialization and Setup --- 
        function setupSpeechRecognition() {
            window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!window.SpeechRecognition) {
                statusMessage.textContent = "Speech recognition not supported by this browser.";
                btnStartRecording.disabled = true; return false;
            }
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US'; // Already in English, good.
            recognition.onresult = handleRecognitionResult;
            recognition.onerror = handleRecognitionError;
            recognition.onend = handleRecognitionEnd;
            return true;
        }

        function handleRecognitionResult(event) {
            let currentInterim = '', currentFinal = '';
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const segment = event.results[i][0].transcript;
                if (event.results[i].isFinal) currentFinal += segment + ' ';
                else currentInterim += segment;
            }
            if (currentFinal) transcriptText += currentFinal;
            spiegazioneArea.textContent = transcriptText + currentInterim;
        }

        function handleRecognitionError(event) {
            statusMessage.textContent = "Recognition error: " + event.error;
            stopRecordingLogic();
        }
        
        function handleRecognitionEnd() {
            // We don't do anything here for now, manual stop handles sending.
        }

        // --- Flow Logic ---
        btnProcessMaterial.addEventListener('click', async () => {
            const pdfFile = pdfFileInput.files[0];
            const textContent = materialeStudioTextarea.value;

            if (!pdfFile && !textContent.trim()) {
                pdfStatusArea.textContent = "Please upload a PDF or paste some text.";
                pdfStatusArea.classList.remove('hidden');
                return;
            }

            pdfStatusArea.textContent = "Processing study material...";
            pdfStatusArea.classList.remove('hidden');
            resultsArea.classList.add('hidden');
            fase2Title.classList.add('hidden');
            recordingControls.classList.add('hidden');
            hideTTSControls();

            const formData = new FormData();
            if (pdfFile) {
                formData.append('pdf_file', pdfFile);
            } else {
                // If no PDF, send text as if it were a dummy PDF
                // Backend will need to be adapted if we want to handle pure text in process_pdf_view
                // For now, backend expects 'pdf_file'. Adapt backend or force a file.
                // ALTERNATIVE: create a separate endpoint for text only, but for now proceed with this.
                 const textBlob = new Blob([textContent], { type: 'text/plain' });
                 formData.append('pdf_file', textBlob, 'context.txt'); 
                 // ^ this sends text as a file, backend will read it as if it were a text PDF.
            }

            try {
                const response = await fetch(processPdfUrl, {
                    method: 'POST',
                    headers: { 'X-CSRFToken': getCookie('csrftoken') },
                    body: formData
                });

                if (!response.ok) {
                    const errorData = await response.json().catch(() => ({ error: response.statusText }));
                    throw new Error(errorData.error || `Server error: ${response.status}`);
                }

                const data = await response.json();
                if (data.success) {
                    pdfStatusArea.textContent = `Agent: "${data.agent_ready_message}"`;
                    fase2Title.classList.remove('hidden');
                    recordingControls.classList.remove('hidden');
                    btnStartRecording.disabled = false;
                    statusMessage.textContent = "Ready to start your explanation.";
                } else {
                    pdfStatusArea.textContent = "Error from backend: " + (data.error || "Unknown error.");
                }
            } catch (error) {
                pdfStatusArea.textContent = "Communication error (Step 1): " + error.message;
            }
        });

        btnStartRecording.addEventListener('click', () => {
            if (!recognition && !setupSpeechRecognition()) return;
            transcriptText = '';
            spiegazioneArea.textContent = "Listening...";
            statusMessage.textContent = "Recording in progress...";
            btnStartRecording.disabled = true;
            btnStopRecording.disabled = false;
            resultsArea.classList.add('hidden');
            hideTTSControls();
            try {
                recognition.start();
            } catch (e) {
                statusMessage.textContent = "Error starting recording: " + e.message;
                btnStartRecording.disabled = false;
            }
        });

        btnStopRecording.addEventListener('click', stopRecordingLogic);

        function stopRecordingLogic() {
            if (recognition) recognition.stop();
            statusMessage.textContent = "Recording stopped. Processing explanation...";
            btnStartRecording.disabled = false; // Re-enable for new recording if needed
            btnStopRecording.disabled = true;

            if (!transcriptText.trim()) {
                resultsArea.classList.remove('hidden');
                feedbackArea.textContent = "No transcribed text to send.";
                hideTTSControls();
                return;
            }
            sendTranscriptionToBackend(transcriptText);
        }

        async function sendTranscriptionToBackend(transcription) {
            resultsArea.classList.remove('hidden');
            feedbackArea.textContent = "Sending explanation to the agent...";
            hideTTSControls();

            const formData = new FormData();
            formData.append('transcription', transcription);
            // Note: We no longer send audio_data or context here, agent uses session.

            try {
                const response = await fetch(processAudioUrl, {
                    method: 'POST',
                    headers: { 'X-CSRFToken': getCookie('csrftoken') },
                    body: formData
                });
                if (!response.ok) {
                    const errorData = await response.json().catch(() => ({ error: response.statusText }));
                    throw new Error(errorData.error || `Server error: ${response.status}`);
                }
                const data = await response.json();
                if (data.success) {
                    agentResponseText = data.agent_response;
                    feedbackArea.textContent = agentResponseText;
                    if (agentResponseText) showTTSControls();
                } else {
                    feedbackArea.textContent = "Error from backend (Step 2): " + (data.error || "Unknown error.");
                }
            } catch (error) {
                feedbackArea.textContent = "Communication error (Step 2): " + error.message;
            }
        }

        // --- TTS Functions ---
        function showTTSControls() { 
            if (ttsControls) ttsControls.style.display = 'block';
            if (btnPlayPauseResponse) { // Ensure button exists
                btnPlayPauseResponse.textContent = "Read Response";
                btnPlayPauseResponse.classList.remove('btn-warning');
                btnPlayPauseResponse.classList.add('btn-success');
            }
        }

        function hideTTSControls() { 
            if (ttsControls) ttsControls.style.display = 'none'; 
            if (typeof window.speechSynthesis !== 'undefined') {
                 window.speechSynthesis.cancel(); // Stop reading if active
            }
        }

        function speakText(text) {
            if (!text || typeof window.speechSynthesis === 'undefined') return;
            
            // If there's an ongoing or paused utterance, stop it before creating a new one
            if (window.speechSynthesis.speaking || window.speechSynthesis.paused) {
                window.speechSynthesis.cancel();
            }

            currentUtterance = new SpeechSynthesisUtterance(text);
            currentUtterance.lang = 'en-US'; // Already English
            currentUtterance.rate = parseFloat(speedControl.value);

            currentUtterance.onstart = () => {
                console.log("TTS started");
                btnPlayPauseResponse.textContent = "Pause";
                btnPlayPauseResponse.classList.remove('btn-success');
                btnPlayPauseResponse.classList.add('btn-warning');
            };

            currentUtterance.onpause = () => {
                console.log("TTS paused");
                btnPlayPauseResponse.textContent = "Resume";
                btnPlayPauseResponse.classList.remove('btn-warning');
                btnPlayPauseResponse.classList.add('btn-success');
            };

            currentUtterance.onresume = () => {
                console.log("TTS resumed");
                btnPlayPauseResponse.textContent = "Pause";
                btnPlayPauseResponse.classList.remove('btn-success');
                btnPlayPauseResponse.classList.add('btn-warning');
            };

            currentUtterance.onend = () => {
                console.log("TTS ended");
                btnPlayPauseResponse.textContent = "Read Response";
                btnPlayPauseResponse.classList.remove('btn-warning');
                btnPlayPauseResponse.classList.add('btn-success');
                currentUtterance = null; // Reset utterance
            };

            currentUtterance.onerror = (event) => {
                console.error("TTS Error:", event);
                btnPlayPauseResponse.textContent = "Read Response";
                btnPlayPauseResponse.classList.remove('btn-warning');
                btnPlayPauseResponse.classList.add('btn-success');
                currentUtterance = null;
            };

            window.speechSynthesis.speak(currentUtterance);
        }

        btnPlayPauseResponse.addEventListener('click', () => {
            if (!agentResponseText) return;

            if (window.speechSynthesis.paused && currentUtterance) {
                window.speechSynthesis.resume();
            } else if (window.speechSynthesis.speaking && currentUtterance) {
                window.speechSynthesis.pause();
            } else {
                // Non sta parlando e non è in pausa, quindi inizia (o ricomincia)
                speakText(agentResponseText);
            }
        });

        btnStopTTSResponse.addEventListener('click', () => {
            if (typeof window.speechSynthesis !== 'undefined') {
                window.speechSynthesis.cancel(); // Questo triggera l'evento onend dell'utterance se attiva
                // L'UI del pulsante PlayPause si resetterà nell'onend.
                // Se non c'era nulla in corso, onend non scatta, quindi resettiamo per sicurezza.
                if (!currentUtterance) { // o se non era speaking/paused
                     btnPlayPauseResponse.textContent = "Read Response";
                     btnPlayPauseResponse.classList.remove('btn-warning');
                     btnPlayPauseResponse.classList.add('btn-success');
                }
            }
        });

        btnReplayResponse.addEventListener('click', () => {
            if (!agentResponseText) return;
            speakText(agentResponseText); // speakText già gestisce il cancel se necessario
        });

        // --- Utility ---
        function getCookie(name) {
            let cookieValue = null;
            if (document.cookie && document.cookie !== '') {
                const cookies = document.cookie.split(';');
                for (let i = 0; i < cookies.length; i++) {
                    const cookie = cookies[i].trim();
                    if (cookie.substring(0, name.length + 1) === (name + '=')) {
                        cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                        break;
                    }
                }
            }
            return cookieValue;
        }
        
        // Stato iniziale UI
        document.addEventListener('DOMContentLoaded', () => {
            fase2Title.classList.add('hidden');
            recordingControls.classList.add('hidden');
            resultsArea.classList.add('hidden');
            hideTTSControls();
            // Setup riconoscimento vocale ma non avviarlo
            if (!recognition) setupSpeechRecognition(); 
        });

    </script>
</body>
</html> 